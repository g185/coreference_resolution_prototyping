module:
  _target_: models.pl_modules.BasePLModule
  optimizer:
    _target_: torch.optim.RAdam
    lr: 6e-6
    weight_decay: 0
  model:
    _target_: models.model.CorefModel
    language_model: "longformer-large-4096"
    huggingface_model_name: "allenai/longformer-large-4096"
    mention_mode: "s2e_sentence_level" #gold, s2e, s2e_sentence_level, s2s
    coreference_mode: "t2c" #gol, t2c, topk, latent
    transformer_freeze: "unfreezed"
    pos_weight: 1
    linear_layer_hidden_size: 1000

