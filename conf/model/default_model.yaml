module:
  _target_: models.pl_modules.BasePLModule
  optimizer:
    _target_: torch.optim.RAdam
    lr: 6e-6
    weight_decay: 0
  model:
    _target_: models.model.CorefModel
    language_model: "longformer-large-4096"
    huggingface_model_name: "allenai/longformer-large-4096"
    mode: "s2s"
    transformer_freeze: "unfreezed"
    pos_weight: 1
    linear_layer_hidden_size: 1000

